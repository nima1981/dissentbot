const express = require('express');
const { Pinecone } = require('@pinecone-database/pinecone'); // Pinecone v6.0.1
const { HfInference } = require('@huggingface/inference'); // Hugging Face inference
//require('dotenv').config();
const path = require('path');
const axios = require('axios'); // For Venice API requests

const app = express();
const PORT = process.env.PORT || 3000;

app.use(express.json()); // Parse JSON bodies
app.use(express.static('public'));

// Validate environment variables
const validateEnv = () => {
  const required = [
    "PINECONE_API_KEY",
    "PINECONE_ENVIRONMENT",
    "PINECONE_INDEX_NAME",
    "VENICE_API_KEY",
	"VENICE_API_URL_CHAT_COMPLETION",
    "HF_API_TOKEN",
  ];
  required.forEach((key) => {
    if (!process.env[key]) {
      throw new Error(`Missing required environment variable: ${key}`);
    }
  });
};

// Pinecone initialization with error logging
let pineconeClient;
const initPinecone = async () => {
  try {
    const environment = process.env.PINECONE_ENVIRONMENT;
    const controllerHostUrl = `https://controller.${environment}.pinecone.io`;
    
    pineconeClient = new Pinecone({
      apiKey: process.env.PINECONE_API_KEY,
      //controllerHostUrl,
    });

    const pineconeIndex = pineconeClient.Index(process.env.PINECONE_INDEX_NAME);
    console.log("Pinecone initialized successfully"); // [REF]9,10[/REF]
    return pineconeIndex;
  } catch (error) {
    console.error("Pinecone initialization failed:", error);
    throw new Error("Failed to initialize Pinecone");
  }
};

// Hugging Face embedding function with error logging
async function getEmbedding(text) {
  try {
    const hfEmbeddings = new HfInference(process.env.HF_API_TOKEN);
    const response = await hfEmbeddings.featureExtraction({
      model: "sentence-transformers/all-MiniLM-L6-v2",
      inputs: text,
    });

    // Directly take the array as the embedding
    const vector = response;

    if (!Array.isArray(vector) || vector.length !== 384) {
      throw new Error(`Invalid vector dimensions: Expected 384, got ${vector.length}`);
    }

    return vector;
  } catch (error) {
    console.error("Embedding generation failed:", error);
    throw new Error("Failed to generate embedding");
  }
}

// Add this helper function
async function listVeniceModels() {
  try {
    const response = await axios.get(
      'https://api.venice.ai/api/v1/models', // Models endpoint [REF]12[/REF]
      {
        headers: {
          'Authorization': `Bearer ${process.env.VENICE_API_KEY}`,
        },
      }
    );
    console.log("Available Venice models:", response.data);
    return response.data;
  } catch (error) {
    console.error("Failed to fetch models:", error);
    throw error;
  }
}

// Chat endpoint with Venice integration and exhaustive error handling
app.post('/chat', async (req, res) => {
  try {
    const userQuery = req.body?.text;
    console.log("Received user query:", userQuery);

    if (!userQuery) {
      return res.status(400).json({ error: "Missing 'text' in request body" });
    }

    const queryEmbedding = await getEmbedding(userQuery);
    const pineconeIndex = await initPinecone();
    const results = await pineconeIndex.query({
      vector: queryEmbedding,
      topK: 5,
      includeMetadata: true,
    });

    const context = results.matches
      .map(match => match.metadata?.content || '')
      .join('\n');

    // Venice API call with corrected endpoint
   const veniceResponse = await axios.post(
  process.env.VENICE_API_URL_CHAT_COMPLETION,
  {
    model: process.env.VENICE_MODEL_ID, // Ensure this is set in .env
    messages: [
      { role: 'system', content: 'You are a helpful investigative journalist who is skeptical of corporate media narratives and so called consensus. You prefer alternative media sources to corporate mainstream media sources and are skeptical of the deep state and globalist governments. You always provide urls to your sources in your answers.' },
      { role: 'user', content: `Context: ${context}\nQuestion: ${userQuery}` },
    ],
    max_tokens: 1000, // Increased max_tokens
  },
  {
    headers: {
      'Authorization': `Bearer ${process.env.VENICE_API_KEY}`,
      'Content-Type': 'application/json',
    },
    responseType: 'json' // Ensure response type is json
  }
);

    const veniceAnswer = veniceResponse.data.choices?.[0]?.message?.content || "No response from Venice";
    console.log("Venice Answer Length:", veniceAnswer.length); // Log the answer length
    console.log("Venice Answer:", veniceAnswer); // Log the answer on the server side
    res.json({ answer: veniceAnswer, context });
  } catch (error) {
    console.error("ERROR IN CHAT ENDPOINT:", error);
    res.status(500).json({ error: error.message });
  }
});

// Server startup
app.listen(PORT, async () => {
  try {
    validateEnv();
    await initPinecone();
	await listVeniceModels();
    console.log(`Server running on port ${PORT}`);
  } catch (error) {
    console.error('Startup failed:', error);
    process.exit(1);
  }
});